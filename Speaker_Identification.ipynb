{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook looks at speaker identification. First using the KNN classifier we have used in other tasks, then using a Gaussian Mixture Model which is commonly used for speaker ID tasks.  \n",
    "\n",
    "See [this page](https://appliedmachinelearning.blog/2017/11/14/spoken-speaker-identification-based-on-gaussian-mixture-models-python-implementation/) another example of using GMMs (but with an older version of scikit-learn). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pysptk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import utils  # our own utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dirname = 'data'\n",
    "iteminfo, speakers = utils.extract_metadata(data_dirname)\n",
    "\n",
    "#all_data = utils.get_data_for(iteminfo, 'language', 'en')\n",
    "all_data = np.array(list(iteminfo.keys()))\n",
    "\n",
    "# get the labels for this list of filenames\n",
    "target = utils.get_data_labels(iteminfo, all_data, 'speaker')\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(datafile):\n",
    "    \"\"\"Generate a mean feature vector for a single data file\n",
    "    return a 1 dimensional numpy array\"\"\"\n",
    "    y, sr = librosa.load(datafile)\n",
    "    mfcc = librosa.feature.mfcc(y, sr=sr, n_mfcc=20)\n",
    "    # normalise the feature vector\n",
    "    mfcc = sklearn.preprocessing.scale(mfcc)\n",
    "    return mfcc.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_features(datafile):\n",
    "    \"\"\"Generate a mean feature vector including delta \n",
    "    features for a single data file\n",
    "    return a 1 dimensional numpy array\"\"\"\n",
    "    y, sr = librosa.load(datafile)\n",
    "    mfcc = librosa.feature.mfcc(y, sr=sr, n_mfcc=20)\n",
    "    # normalise the feature vector\n",
    "    mfcc = sklearn.preprocessing.scale(mfcc)\n",
    "    delta = librosa.feature.delta(mfcc)\n",
    "    feat = np.concatenate([mfcc, delta])\n",
    "    return feat.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440, 20)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([features(d) for d in all_data])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220, 20)\n",
      "(220, 20)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.50)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        10a       0.75      0.67      0.71         9\n",
      "        10b       1.00      0.91      0.95        11\n",
      "        11b       0.62      1.00      0.76         8\n",
      "        11c       1.00      1.00      1.00         9\n",
      "         1b       0.71      0.38      0.50        13\n",
      "         1c       1.00      0.89      0.94         9\n",
      "         2C       0.88      0.70      0.78        10\n",
      "         2d       0.24      1.00      0.39         6\n",
      "         3a       1.00      0.92      0.96        12\n",
      "         3b       0.44      0.36      0.40        11\n",
      "         4c       0.70      0.78      0.74         9\n",
      "         4d       0.45      0.82      0.58        11\n",
      "         5a       1.00      0.18      0.31        11\n",
      "         5b       0.90      0.90      0.90        10\n",
      "          6       0.67      0.18      0.29        11\n",
      "        6gb       1.00      0.69      0.82        13\n",
      "         7a       0.62      0.89      0.73         9\n",
      "         7b       1.00      0.86      0.92         7\n",
      "         8b       1.00      0.89      0.94         9\n",
      "         8d       1.00      0.13      0.24        15\n",
      "         9a       0.50      0.42      0.45        12\n",
      "         9c       0.26      1.00      0.42         5\n",
      "\n",
      "avg / total       0.78      0.66      0.66       220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = knn.predict(X_test)\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker Identification with GMM\n",
    "\n",
    "Try using a GMM to model each speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352,), (88,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# For speaker id we split the data so that we have four items for each \n",
    "# speaker (two english, two chinese) reserved for testing\n",
    "\n",
    "train_files = utils.get_data_for(iteminfo, 'item', ['3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "\n",
    "# split training data by speaker\n",
    "speakerdata = {}\n",
    "for fname in train_files:\n",
    "    spkr = iteminfo[fname]['speaker']\n",
    "    if spkr in speakerdata:\n",
    "        speakerdata[spkr].append(fname)\n",
    "    else:\n",
    "        speakerdata[spkr] = [fname]\n",
    "\n",
    "test_files = utils.get_data_for(iteminfo, 'item', ['1', '2'])\n",
    "train_files.shape, test_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_features(datafile, label):\n",
    "    \"\"\"Generate mfcc feature vectors for a single data file\n",
    "    return a 2 dimensional numpy array with one row per frame\n",
    "    and an array of labels for each frame\"\"\"\n",
    "    y, sr = librosa.load(datafile)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    mfcc = sklearn.preprocessing.scale(mfcc)\n",
    "    delta = librosa.feature.delta(mfcc)\n",
    "    labels = np.full((mfcc.shape[1],), label)\n",
    "    return np.hstack((mfcc, delta)).T, labels\n",
    "\n",
    "def extract_frame_features(datafiles, target):\n",
    "    \"\"\"Given a list of sound files and their target labels\n",
    "    Compute a sequence of features for each file\n",
    "    Concatenate these features into a single np.array\n",
    "    Return these features and a corresponding array\n",
    "    of target labels, one for every frame\"\"\"\n",
    "    \n",
    "    data = None\n",
    "    frame_target = []\n",
    "    for i in range(len(target)):\n",
    "        frames, labels = frame_features(datafiles[i], target[i])\n",
    "        frame_target.extend(labels)\n",
    "        if data is None:\n",
    "            # transpose the frames \n",
    "            data = frames\n",
    "        else:\n",
    "            # concatenate the tranposed frames\n",
    "            data = np.concatenate((data, frames))\n",
    "\n",
    "    frame_target = np.array(frame_target)\n",
    "    \n",
    "    return data, frame_target\n",
    "\n",
    "#data, target = extract_frame_features(datafiles, target)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32496, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='full', init_params='kmeans', max_iter=100,\n",
       "        means_init=None, n_components=1, n_init=1, precisions_init=None,\n",
       "        random_state=None, reg_covar=1e-06, tol=0.001, verbose=0,\n",
       "        verbose_interval=10, warm_start=True, weights_init=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the UBM\n",
    "target = utils.get_data_labels(iteminfo, train_files, 'speaker')\n",
    "data, target = extract_frame_features(train_files, target)\n",
    "\n",
    "print(data.shape)\n",
    "ubm = GaussianMixture(n_components=1, warm_start=True)\n",
    "ubm.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'7b', '3b', '1b', '2d', '6', '5b', '2C', '9c', '4c', '6gb', '1c', '10a', '4d', '5a', '10b', '9a', '11c', '11b', '7a', '3a', '8d', '8b'}\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def model_speaker(ubm, speakerdata):\n",
    "    \"\"\"use data from one\n",
    "    speaker to train a GMM for that speaker,\n",
    "    return the adapted model\"\"\"\n",
    "    \n",
    "    sp_model = GaussianMixture(n_components=5)\n",
    "    target = np.full(len(speakerdata), 'x')\n",
    "    data, target = extract_frame_features(speakerdata, target)\n",
    "    \n",
    "    sp_model.fit(data)\n",
    "    \n",
    "    return sp_model\n",
    "\n",
    "test_target = utils.get_data_labels(iteminfo, test_files, 'speaker')\n",
    "speakers = set(test_target)\n",
    "print(speakers)\n",
    "models = {}\n",
    "for speaker in speakers:\n",
    "    models[speaker] = model_speaker(ubm, speakerdata[speaker])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_speaker(models, datafile):\n",
    "\n",
    "    data, target = frame_features(datafile, 'x')\n",
    "    scores = []\n",
    "    for spkr in models:\n",
    "        score = models[spkr].score(data)\n",
    "        scores.append((score, spkr))\n",
    "    return scores\n",
    "\n",
    "import os\n",
    "\n",
    "allscores = {}\n",
    "for fname in test_files:\n",
    "    scores = identify_speaker(models, fname)\n",
    "    allscores[os.path.basename(fname)] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1b_F_Ch_01.wav [(-283.33644667343754, '11b'), (-194.1239778655229, '5b')]\n",
      "1b_F_Ch_02.wav [(-336.48171013744883, '5b'), (-243.15703369990405, '11b')]\n",
      "1b_F_En_01.wav [(-466.28436155675121, '11b'), (-29.613564482770837, '3a')]\n",
      "1b_F_En_02.wav [(-105.47306926260845, '11b'), (-6.2579101713362713, '3a')]\n",
      "1c_M_Ch_01.wav [(-9367.1348931996636, '5b'), (-1487.9530709369119, '11b')]\n",
      "1c_M_Ch_02.wav [(-13152.959855078836, '5b'), (-2104.9762360846389, '11b')]\n",
      "1c_M_En_01.wav [(-7330.9516421427224, '5b'), (-1622.3547473973872, '11b')]\n",
      "1c_M_En_02.wav [(-5558.2052874961355, '5b'), (-910.497037810493, '11b')]\n",
      "2C-W-Ch-01.wav [(-9371.6887264968464, '5b'), (-2049.7145808099817, '11b')]\n",
      "2C-W-Ch-02.wav [(-4914.6579828333306, '5b'), (-1271.2126526227034, '11b')]\n",
      "2C-W-En--01.wav [(-10503.712566896693, '5b'), (-2034.3582624112025, '11b')]\n",
      "2C-W-En--02.wav [(-6647.8014470710486, '5b'), (-1430.4150137133495, '11b')]\n",
      "2d_M_Ch_01.wav [(-6976.2697786799281, '5b'), (-530.13553481249392, '11b')]\n",
      "2d_M_Ch_02.wav [(-8496.8550240580771, '5b'), (-541.21477847574897, '11b')]\n",
      "2d_M_En_01.wav [(-2715.5263414632136, '5b'), (-186.67015340195988, '11b')]\n",
      "2d_M_En_02.wav [(-1249.6685653067523, '5b'), (-50.011144206926382, '11b')]\n",
      "3a-M-Ch-1.wav [(-5577.2784521839594, '5b'), (-787.52349571692707, '11b')]\n",
      "3a-M-Ch-2.wav [(-5868.6374963144699, '5b'), (-679.30670798234871, '11b')]\n",
      "3a-M-En-1.wav [(-4829.2804655651025, '5b'), (-534.16249162540555, '11b')]\n",
      "3a-M-En-2.wav [(-2086.7501718775916, '5b'), (-204.58517389611484, '11b')]\n",
      "3b_F_Ch-01.wav [(-2020.1312690790905, '5b'), (-279.8392083242428, '11b')]\n",
      "3b_F_Ch-02.wav [(-1934.7267998885025, '5b'), (-76.614528626355124, '11b')]\n",
      "3b_F_En-01.wav [(-676.92699458258505, '5b'), (-255.75890193265656, '11b')]\n",
      "3b_F_En-02.wav [(-363.22862097087562, '5b'), (-37.118717690471939, '11b')]\n",
      "4c_F_Ch_01.wav [(-4586.4048345411411, '5b'), (-78.509853952158579, '1b')]\n",
      "4c_F_Ch_02.wav [(-3214.6841982557316, '5b'), (-31.691664642875619, '1b')]\n",
      "4c_F_En_01.wav [(-2080.251117189976, '5b'), (-71.234640236538709, '11b')]\n",
      "4c_F_En_02.wav [(-982.98204154800521, '5b'), (-21.082604820926846, '11b')]\n",
      "4d_M_Ch_01.wav [(-1222.8715218975956, '5b'), (-569.80164555011095, '11b')]\n",
      "4d_M_Ch_02.wav [(-849.3508355822164, '5b'), (-162.97891130538071, '11b')]\n",
      "4d_M_En_01.wav [(-383.32263171526796, '11b'), (-261.80523396720292, '5b')]\n",
      "4d_M_En_02.wav [(-451.14795792960638, '5b'), (-165.64208989752848, '11b')]\n",
      "5a-f-ch-01.wav [(-7298.6912929439904, '5b'), (-875.02194850684737, '11b')]\n",
      "5a-f-ch-02.wav [(-9227.7981764173201, '5b'), (-925.22273850649401, '11b')]\n",
      "5a-f-en-01.wav [(-3909.8870655929177, '5b'), (-637.05987782717875, '11b')]\n",
      "5a-f-en-02.wav [(-2827.4227468644999, '5b'), (-340.30752496717429, '11b')]\n",
      "5b_M_Ch-01.wav [(-191.36813533937706, '11b'), (-19.193763966710897, '3a')]\n",
      "5b_M_Ch-02.wav [(-176.30065176503911, '11b'), (-31.557820187198718, '3a')]\n",
      "5b_M_En-01.wav [(-211.79695267173727, '11b'), (-1.7998063701108149, '6')]\n",
      "5b_M_En-02.wav [(-201.55576378930093, '11b'), (-10.040258437429406, '6')]\n",
      "6_W_CH_-01.wav [(-3849.7155538457264, '5b'), (-135.91630085288858, '11b')]\n",
      "6_W_CH_-02.wav [(-3928.8652856072404, '5b'), (-97.438830505468999, '11b')]\n",
      "6_W_EN_-01.wav [(-758.80491091702334, '5b'), (-100.19760473780971, '11b')]\n",
      "6_W_EN_-02.wav [(-771.11990367457292, '5b'), (-16.612669407253954, '11b')]\n",
      "6_gb_M_CN_-01.wav [(-3282.2495092027916, '5b'), (-308.29375715310999, '11b')]\n",
      "6_gb_M_CN_-02.wav [(-5075.7776292656608, '5b'), (-436.58702557969389, '11b')]\n",
      "6_gb_M_EN_-01.wav [(-1446.7562051440923, '5b'), (-538.4951000012644, '11b')]\n",
      "6_gb_M_EN_-02.wav [(-3253.1723559044826, '5b'), (-380.75849013604517, '11b')]\n",
      "7a_F_Ch_-01.wav [(-5664.0021806616751, '5b'), (-444.67054669919702, '11b')]\n",
      "7a_F_Ch_-02.wav [(-2630.5038287856678, '5b'), (-332.65111672981965, '11b')]\n",
      "7a_F_En_-01.wav [(-3274.0630477583854, '5b'), (-405.50834861233335, '11b')]\n",
      "7a_F_En_-02.wav [(-2544.0637952696675, '5b'), (-148.59958841660261, '11b')]\n",
      "7b-M-Ch-01.wav [(-19446.71779298313, '5b'), (-3764.8942428133678, '11b')]\n",
      "7b-M-Ch-02.wav [(-24080.896781881391, '5b'), (-3218.7376858248822, '11b')]\n",
      "7b-M-EN-01.wav [(-5526.8780718403696, '5b'), (-444.97383208390102, '11b')]\n",
      "7b-M-EN-02.wav [(-4593.1034574484593, '5b'), (-445.9503896229935, '11b')]\n",
      "8b_M_Ch_-01.wav [(-5126.9880044142128, '5b'), (-100.52527587580565, '11b')]\n",
      "8b_M_Ch_-02.wav [(-3009.0568790589646, '5b'), (-34.851849354443026, '11b')]\n",
      "8b_M_En_-01.wav [(-505.54277317309692, '11b'), (-357.48711811871857, '5b')]\n",
      "8b_M_En_-02.wav [(-238.65342447262196, '11b'), (-53.677416409342101, '5b')]\n",
      "8d_F_Ch_-01.wav [(-547.5283133118927, '5b'), (-17.007551092858076, '11b')]\n",
      "8d_F_Ch_-02.wav [(-725.25828211582143, '5b'), (-6.0739143694729787, '11b')]\n",
      "8d_F_En_-01.wav [(-934.37942745475789, '5b'), (-263.63949849010675, '11b')]\n",
      "8d_F_En_-02.wav [(-698.37209489218344, '5b'), (-143.08316617041436, '11b')]\n",
      "9a_F_Ch_01.wav [(-3716.81201254095, '5b'), (-162.77263205197571, '11b')]\n",
      "9a_F_Ch_02.wav [(-2812.5244066544856, '5b'), (-32.904546354799436, '11b')]\n",
      "9a_F_En-01.wav [(-3679.5573508117295, '5b'), (-119.12516727901857, '11b')]\n",
      "9a_F_En-02.wav [(-2844.457675177262, '5b'), (-165.60105135287623, '11b')]\n",
      "9c_M_Ch_01.wav [(-948.57707774357425, '5b'), (-6.3562244994970785, '11b')]\n",
      "9c_M_Ch_02.wav [(-1485.3181981758569, '5b'), (-78.937358824580741, '11b')]\n",
      "9c_M_En_01.wav [(-598.94919153552678, '5b'), (-107.01322136637019, '11b')]\n",
      "9c_M_En_02.wav [(-94.472861651239796, '5b'), (-24.619191528897119, '11b')]\n",
      "10a_F_Ch_01.wav [(-17565.805143999951, '5b'), (-2121.0548946719173, '11b')]\n",
      "10a_F_Ch_02.wav [(-18401.705407194058, '5b'), (-3418.4694438626625, '11b')]\n",
      "10a_F_En_01.wav [(-12004.703746537063, '5b'), (-690.03194129235465, '11b')]\n",
      "10a_F_En_02.wav [(-5264.9054797373919, '5b'), (-82.59134000671952, '1b')]\n",
      "10b_M_Ch_01.wav [(-10074.991871924643, '5b'), (-2334.0853477842652, '11b')]\n",
      "10b_M_Ch_02.wav [(-12697.330688971279, '5b'), (-3586.7559214947023, '11b')]\n",
      "10b_M_En_01.wav [(-1072.6704554164585, '5b'), (-749.69882163031957, '11b')]\n",
      "10b_M_En_02.wav [(-751.01187732091796, '5b'), (-371.39149061736282, '11b')]\n",
      "11b_M_Ch_01.wav [(-806.69063318267092, '5b'), (15.448004008976195, '3a')]\n",
      "11b_M_Ch_02.wav [(-1221.498981539746, '5b'), (5.6330875053762917, '1b')]\n",
      "11b_M_En_01.wav [(-1204.7749656356652, '5b'), (-1.3870056828286259, '1b')]\n",
      "11b_M_En_02.wav [(-659.5686950498565, '5b'), (16.984148303057331, '3a')]\n",
      "11c_F_Ch_01.wav [(-7437.7783341108043, '5b'), (-821.60679779269924, '11b')]\n",
      "11c_F_Ch_02.wav [(-5633.1427577308059, '5b'), (-577.66978923130739, '11b')]\n",
      "11c_F_En_01.wav [(-7009.1182881770083, '5b'), (-795.14139949976175, '11b')]\n",
      "11c_F_En_02.wav [(-4979.0960984876574, '5b'), (-365.17798753627358, '11b')]\n"
     ]
    }
   ],
   "source": [
    "for fn in test_files:\n",
    "    s = sorted(allscores[os.path.basename(fn)])\n",
    "    print(os.path.basename(fn), s[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files[10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
